# üöÄ RKE2 + Rancher HA Installer - Configuraci√≥n Centralizada
# Archivo de configuraci√≥n principal para todo el stack
# Copia este archivo como .env y ajusta los valores seg√∫n tu entorno

# =======================================
# üåç CONFIGURACI√ìN B√ÅSICA
# =======================================

# Contrase√±a SSH unificada para todos los nodos (OBLIGATORIO)
# ‚ö†Ô∏è  CR√çTICO: Todos los nodos deben tener la misma contrase√±a SSH para root
ROOT_PASSWORD=TuPasswordSeguraAqui

# IP del LoadBalancer externo (NGINX Plus)
LB_IP=192.168.1.50

# Configuraci√≥n SSH
SSH_PORT=22
SSH_USER=root

# =======================================
# üè∑Ô∏è CONFIGURACI√ìN DE SUBDOMINIOS (NUEVO ENFOQUE)
# =======================================

# üåê Enfoque elegante con subdominios separados
# Todos los servicios responden por puerto 443 (HTTPS)
RANCHER_DOMAIN=rancher.midominio.com     # Rancher UI
K8S_API_DOMAIN=api.midominio.com         # Kubernetes API
K8S_REG_DOMAIN=reg.midominio.com         # RKE2 Registration

# üì° DNS Records necesarios:
# 192.168.1.50    api.midominio.com
# 192.168.1.50    reg.midominio.com  
# 192.168.1.50    rancher.midominio.com

# =======================================
# üîê CREDENCIALES Y VERSIONES
# =======================================

# Contrase√±a admin para Rancher (primera configuraci√≥n)
BOOTSTRAP_PASSWORD=AdminPassword123

# Versiones de software
RKE2_VERSION=v1.32.1+rke2r1
RANCHER_VERSION=v2.11.1

# Token para unir nodos al cluster (generado autom√°ticamente si est√° vac√≠o)
CLUSTER_TOKEN=TokenSuperSeguro123

# =======================================
# üåê CONFIGURACI√ìN DE RED
# =======================================

# Rango de IPs para MetalLB LoadBalancer
# Debe estar en la misma red que los nodos pero no en uso
METALLB_IP_RANGE=192.168.1.200-192.168.1.210

# CIDR para pods (interno)
POD_CIDR=10.42.0.0/16

# CIDR para servicios (interno)
SERVICE_CIDR=10.43.0.0/16

# Interface de red principal (auto-detectado si est√° vac√≠o)
NETWORK_INTERFACE=""

# =======================================
# üèóÔ∏è CONFIGURACI√ìN DE NODOS (JSON)
# =======================================

# üÜï CARACTER√çSTICA PRINCIPAL: Configuraci√≥n unificada en formato JSON
# Todos los nodos con sus IPs, tipos y roles definidos aqu√≠
# Tipos disponibles: master, worker, storage
# primary: true solo para el master principal (uno por cluster)

NODES_CONFIG='{
  "prd3appk8sm1": {
    "ip": "192.168.1.101", 
    "type": "master", 
    "primary": true,
    "hostname": "prd3appk8sm1.midominio.com"
  },
  "prd3appk8sm2": {
    "ip": "192.168.1.102", 
    "type": "master", 
    "primary": false,
    "hostname": "prd3appk8sm2.midominio.com"
  },
  "prd3appk8sm3": {
    "ip": "192.168.1.103", 
    "type": "master", 
    "primary": false,
    "hostname": "prd3appk8sm3.midominio.com"
  },
  "prd3appk8sw1": {
    "ip": "192.168.1.111", 
    "type": "worker", 
    "primary": false,
    "hostname": "prd3appk8sw1.midominio.com"
  },
  "prd3appk8sw2": {
    "ip": "192.168.1.112", 
    "type": "worker", 
    "primary": false,
    "hostname": "prd3appk8sw2.midominio.com"
  },
  "prd3appk8sw3": {
    "ip": "192.168.1.113", 
    "type": "worker", 
    "primary": false,
    "hostname": "prd3appk8sw3.midominio.com"
  },
  "prd3appk8ss1": {
    "ip": "192.168.1.121", 
    "type": "storage", 
    "primary": false,
    "hostname": "prd3appk8ss1.midominio.com"
  },
  "prd3appk8ss2": {
    "ip": "192.168.1.122", 
    "type": "storage", 
    "primary": false,
    "hostname": "prd3appk8ss2.midominio.com"
  },
  "prd3appk8ss3": {
    "ip": "192.168.1.123", 
    "type": "storage", 
    "primary": false,
    "hostname": "prd3appk8ss3.midominio.com"
  }
}'

# üìã EXPLICACI√ìN DE TIPOS DE NODOS:
# - master: Ejecuta etcd, kube-apiserver, kube-scheduler, kube-controller-manager
# - worker: Ejecuta kubelet, kube-proxy, workloads de aplicaciones
# - storage: Ejecuta kubelet + Ceph OSDs para almacenamiento distribuido

# =======================================
# üíæ CONFIGURACI√ìN DE ALMACENAMIENTO
# =======================================

# Disco para Ceph en nodos storage (debe existir y estar sin particionar)
CEPH_DISK=/dev/sdb

# Tama√±o de pool de r√©plicas para Ceph
CEPH_REPLICA_SIZE=3

# StorageClass por defecto
DEFAULT_STORAGE_CLASS=rook-ceph-block

# =======================================
# üîß CONFIGURACIONES AVANZADAS
# =======================================

# Modo de instalaci√≥n (full, no-rancher, only-k8s)
INSTALL_MODE=full

# CNI Plugin (calico por defecto en RKE2)
CNI_PLUGIN=calico

# Habilitar audit logs
ENABLE_AUDIT=true

# Backup autom√°tico de etcd (intervalo en horas)
ETCD_BACKUP_INTERVAL=6

# Retenci√≥n de backups (en d√≠as)
ETCD_BACKUP_RETENTION=7

# =======================================
# üõ°Ô∏è CONFIGURACI√ìN DE SEGURIDAD
# =======================================

# Habilitar Pod Security Standards
ENABLE_POD_SECURITY=true

# Habilitar Network Policies
ENABLE_NETWORK_POLICIES=true

# Certificados SSL autom√°ticos con Let's Encrypt
ENABLE_LETSENCRYPT=false

# Email para Let's Encrypt (obligatorio si ENABLE_LETSENCRYPT=true)
LETSENCRYPT_EMAIL=""

# =======================================
# üìä CONFIGURACI√ìN DE MONITOREO
# =======================================

# Habilitar m√©tricas de sistema
ENABLE_METRICS=true

# Namespace para componentes del sistema
SYSTEM_NAMESPACE=cattle-system

# Timeout para operaciones kubectl (segundos)
KUBECTL_TIMEOUT=300

# =======================================
# üåç CONFIGURACI√ìN REGIONAL
# =======================================

# Zona horaria
TIMEZONE=America/Lima

# Idioma del sistema
LOCALE=es_PE.UTF-8

# Servidor NTP
NTP_SERVERS="pool.ntp.org"

# =======================================
# üîç CONFIGURACI√ìN DE LOGGING
# =======================================

# Nivel de log (debug, info, warn, error)
LOG_LEVEL=info

# Habilitar logs detallados
VERBOSE_LOGGING=false

# Directorio de logs
LOG_DIR=./logs

# =======================================
# ‚ö° CONFIGURACIONES DE PERFORMANCE
# =======================================

# Recursos m√°ximos por nodo
MAX_PODS_PER_NODE=250

# Intervalo de sincronizaci√≥n del kubelet (segundos)
KUBELET_SYNC_INTERVAL=10

# Timeout para joins de nodos (segundos)
NODE_JOIN_TIMEOUT=600

# =======================================
# üß™ CONFIGURACIONES DE DESARROLLO/TEST
# =======================================

# Habilitar modo debug
DEBUG_MODE=false

# Saltar validaciones de prerequisitos (NO recomendado en producci√≥n)
SKIP_PREREQ_CHECK=false

# Limpiar configuraciones previas
CLEAN_INSTALL=false

# Habilitar dry-run (solo mostrar comandos sin ejecutar)
DRY_RUN=false

# =======================================
# üìù NOTAS IMPORTANTES
# =======================================

# üî¥ ANTES DE EJECUTAR:
# 1. Configurar DNS para los subdominios arriba definidos
# 2. Asegurar que todos los nodos tengan la misma contrase√±a SSH
# 3. Verificar que el disco CEPH_DISK existe en nodos storage
# 4. Configurar NGINX Plus en la IP definida como LB_IP
# 5. Validar conectividad entre todos los nodos

# üîß COMANDOS √öTILES:
# - Validar JSON: echo "$NODES_CONFIG" | jq .
# - Ver configuraci√≥n: source .env && env | grep -E "(RANCHER|K8S|NODES)"
# - Test conectividad: ping -c 1 $LB_IP

# üìö DOCUMENTACI√ìN:
# - README.md: Instrucciones generales
# - docs/nginx-plus.md: Configuraci√≥n de LoadBalancer
# - docs/index.md: Documentaci√≥n t√©cnica completa

# =======================================
# üéØ EJEMPLO DE MIGRACI√ìN DESDE VERSI√ìN ANTERIOR
# =======================================

# Versi√≥n anterior (hardcodeado):
# NODES=("server1" "server2" "server3")
# RANCHER_HOSTNAME=rancher.example.com

# Nueva versi√≥n (JSON + subdominios):
# NODES_CONFIG='{"server1": {"ip": "1.1.1.1", "type": "master", "primary": true}, ...}'
# RANCHER_DOMAIN=rancher.example.com
# K8S_API_DOMAIN=api.example.com
