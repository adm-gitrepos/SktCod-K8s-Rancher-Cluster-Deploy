#!/bin/bash
# ============================================================
# Biblioteca de funciones para manejo din√°mico de nodos basado en NODES_CONFIG
# Autor: @SktCod.ByChisto
# Versi√≥n: 2.0

set -euo pipefail
trap 'echo "‚ùå Error en l√≠nea $LINENO durante prueba de alta disponibilidad. Revisa el log." && exit 1' ERR

# Cargar variables y funciones
[ -f .env ] && source .env || { echo "‚ùå Falta archivo .env"; exit 1; }
[ -f scripts/node-helpers.sh ] && source scripts/node-helpers.sh || { echo "‚ùå Falta archivo scripts/node-helpers.sh"; exit 1; }

LOG="logs/07-test-ha-$(date +%F-%H%M).log"
mkdir -p logs && exec > >(tee -a "$LOG") 2>&1

echo "üîÑ Iniciando pruebas de alta disponibilidad..."

# 1. CONFIGURACI√ìN INICIAL
# ========================
validate_nodes_config

# Validar configuraci√≥n de subdominios
validate_subdomain_config

export PATH=$PATH:/var/lib/rancher/rke2/bin
export KUBECONFIG=${KUBECONFIG:-/etc/rancher/rke2/rke2.yaml}

# Verificar que kubeconfig use el endpoint correcto
if ! grep -q "$K8S_API_DOMAIN" "$KUBECONFIG" 2>/dev/null; then
  echo "‚ö†Ô∏è  Warning: kubeconfig no apunta a $K8S_API_DOMAIN"
  echo "üí° Ejecuta primero: scripts/02-install-cluster.sh"
fi

# Verificar kubectl
if ! command -v kubectl &>/dev/null; then
  echo "‚ùå kubectl no est√° disponible"
  exit 1
fi

# Verificar acceso al cl√∫ster
if ! kubectl get nodes &>/dev/null; then
  echo "‚ùå No se puede acceder al cl√∫ster Kubernetes"
  exit 1
fi

# Obtener informaci√≥n de nodos
PRIMARY_MASTER=$(get_primary_master)
SECONDARY_MASTERS=$(get_secondary_masters)
MASTER_COUNT=$(echo "$NODES_CONFIG" | jq -r '[to_entries[] | select(.value.type == "master")] | length')

echo "üìä Configuraci√≥n de HA detectada:"
echo "   ‚Ä¢ Master principal: $PRIMARY_MASTER"
echo "   ‚Ä¢ Masters secundarios: $(echo "$SECONDARY_MASTERS" | tr '\n' ' ' | xargs)"
echo "   ‚Ä¢ Total masters: $MASTER_COUNT"

if [ "$MASTER_COUNT" -lt 2 ]; then
  echo "‚ö†Ô∏è  Solo hay $MASTER_COUNT master(s) configurado(s)"
  echo "üí° Para pruebas de HA se recomiendan al menos 2 masters"
  echo "üîÑ ¬øContinuar de todas formas? (y/N)"
  read -r -n 1 response
  echo
  if [[ ! "$response" =~ ^[Yy]$ ]]; then
    echo "‚ùå Pruebas de HA canceladas por el usuario"
    exit 0
  fi
fi

# 2. ESTADO INICIAL DEL CL√öSTER
# =============================
echo ""
echo "üìä ESTADO INICIAL DEL CL√öSTER"
echo "=============================="

echo "üñ•Ô∏è  Nodos del cl√∫ster:"
kubectl get nodes -o wide

echo ""
echo "üß† Quorum de etcd:"
kubectl get endpoints etcd -n kube-system -o yaml | grep -A 10 "addresses:" || echo "‚ö†Ô∏è  No se pudo obtener informaci√≥n de etcd"

echo ""
echo "üîç Pods cr√≠ticos del sistema:"
kubectl get pods -n kube-system -l component=etcd -o wide
kubectl get pods -n kube-system -l component=kube-apiserver -o wide

# Verificar servicios cr√≠ticos antes de la prueba
echo ""
echo "üöÄ Estado de Rancher (si est√° instalado):"
if kubectl get namespace cattle-system &>/dev/null; then
  kubectl get pods -n cattle-system -l app=rancher -o wide
else
  echo "   ‚ö†Ô∏è  Rancher no est√° instalado"
fi

# 3. CREAR APLICACI√ìN DE MONITOREO
# ================================
echo ""
echo "üì¶ CREANDO APLICACI√ìN DE MONITOREO HA"
echo "======================================"

# Limpiar aplicaci√≥n previa si existe
kubectl delete -f ha-test-app.yaml --ignore-not-found &>/dev/null || true
sleep 5

echo "üß™ Desplegando aplicaci√≥n de monitoreo..."

cat > ha-test-app.yaml <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ha-test-app
  namespace: default
  labels:
    app: ha-test-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: ha-test-app
  template:
    metadata:
      labels:
        app: ha-test-app
    spec:
      containers:
      - name: nginx
        image: nginx:alpine
        ports:
        - containerPort: 80
        resources:
          requests:
            memory: "32Mi"
            cpu: "25m"
          limits:
            memory: "64Mi"
            cpu: "50m"
        readinessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 5
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 10
          periodSeconds: 10
      # Anti-afinidad para distribuir pods en diferentes nodos
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - ha-test-app
              topologyKey: kubernetes.io/hostname
---
apiVersion: v1
kind: Service
metadata:
  name: ha-test-service
  namespace: default
  labels:
    app: ha-test-app
spec:
  type: LoadBalancer
  selector:
    app: ha-test-app
  ports:
  - port: 80
    targetPort: 80
    protocol: TCP
    name: http
EOF

kubectl apply -f ha-test-app.yaml

# Esperar a que la aplicaci√≥n est√© lista
echo "‚è≥ Esperando que la aplicaci√≥n de monitoreo est√© lista..."
kubectl wait --for=condition=Available deployment/ha-test-app --timeout=120s

echo "‚úÖ Aplicaci√≥n de monitoreo desplegada"
kubectl get pods -l app=ha-test-app -o wide

# 4. FUNCI√ìN DE MONITOREO CONTINUO
# ================================
start_monitoring() {
  echo "üìä Iniciando monitoreo continuo en background..."
  
  # Crear script de monitoreo
  cat > monitor-cluster.sh <<'EOF'
#!/bin/bash
LOG_FILE="ha-monitor-$(date +%F-%H%M).log"
echo "$(date): Iniciando monitoreo HA" >> "$LOG_FILE"

while true; do
  TIMESTAMP=$(date '+%Y-%m-%d %H:%M:%S')
  
  # Verificar acceso al API
  if kubectl get nodes &>/dev/null; then
    API_STATUS="‚úÖ OK"
  else
    API_STATUS="‚ùå FAIL"
  fi
  
  # Verificar aplicaci√≥n de prueba
  READY_PODS=$(kubectl get pods -l app=ha-test-app --no-headers 2>/dev/null | grep -c "Running" || echo "0")
  TOTAL_PODS=$(kubectl get pods -l app=ha-test-app --no-headers 2>/dev/null | wc -l || echo "0")
  
  # Verificar servicio LoadBalancer
  LB_IP=$(kubectl get service ha-test-service -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null || echo "")
  if [ -n "$LB_IP" ] && curl -s --max-time 3 "http://$LB_IP" | grep -q "nginx" &>/dev/null; then
    LB_STATUS="‚úÖ OK"
  else
    LB_STATUS="‚ùå FAIL"
  fi
  
  # Verificar Rancher (si existe)
  if kubectl get namespace cattle-system &>/dev/null; then
    RANCHER_PODS=$(kubectl get pods -n cattle-system -l app=rancher --no-headers 2>/dev/null | grep -c "Running" || echo "0")
    RANCHER_STATUS="Rancher: $RANCHER_PODS/3"
  else
    RANCHER_STATUS="Rancher: N/A"
  fi
  
  echo "$TIMESTAMP | API: $API_STATUS | Pods: $READY_PODS/$TOTAL_PODS | LB: $LB_STATUS | $RANCHER_STATUS" | tee -a "$LOG_FILE"
  sleep 10
done
EOF

  chmod +x monitor-cluster.sh
  ./monitor-cluster.sh &
  MONITOR_PID=$!
  echo "üìä Monitoreo iniciado (PID: $MONITOR_PID)"
  return $MONITOR_PID
}

stop_monitoring() {
  local monitor_pid=$1
  if kill "$monitor_pid" 2>/dev/null; then
    echo "üìä Monitoreo detenido"
  fi
  rm -f monitor-cluster.sh
}

# 5. PRUEBA 1: SIMULACI√ìN DE FALLA DEL MASTER PRINCIPAL
# =====================================================
echo ""
echo "üî• PRUEBA 1: FALLA DEL MASTER PRINCIPAL"
echo "========================================"

# Iniciar monitoreo
start_monitoring
MONITOR_PID=$!

echo "‚ö†Ô∏è  Simulando falla del master principal: $PRIMARY_MASTER"
echo "üîÑ Esta prueba puede tomar varios minutos..."

# Guardar estado actual
echo "üìä Estado antes de la falla:"
kubectl get nodes | grep "$PRIMARY_MASTER"
kubectl get pods -n kube-system -l component=etcd | grep "$PRIMARY_MASTER" || echo "‚ö†Ô∏è  etcd pod no encontrado en $PRIMARY_MASTER"

# Simular falla deteniendo RKE2
echo "üõë Deteniendo RKE2 en $PRIMARY_MASTER..."
ssh -p "$SSH_PORT" "$SSH_USER@$PRIMARY_MASTER" "systemctl stop rke2-server" || {
  echo "‚ùå Error al detener RKE2 en $PRIMARY_MASTER"
  stop_monitoring $MONITOR_PID
  exit 1
}

echo "‚è≥ Esperando 30 segundos para que se detecte la falla..."
sleep 30

# Verificar que el cl√∫ster siga funcionando
echo "üîç Verificando continuidad del cl√∫ster..."

for i in {1..12}; do
  echo "üìä Verificaci√≥n $i/12 ($(date '+%H:%M:%S')):"
  
  # Verificar acceso al API
  if kubectl get nodes &>/dev/null; then
    echo "   ‚úÖ API Server accesible"
    
    # Verificar estado de nodos
    NODE_STATUS=$(kubectl get node "$PRIMARY_MASTER" -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}' 2>/dev/null || echo "Unknown")
    echo "   üìç Estado de $PRIMARY_MASTER: $NODE_STATUS"
    
    # Verificar aplicaci√≥n de prueba
    READY_PODS=$(kubectl get pods -l app=ha-test-app --no-headers | grep -c "Running" || echo "0")
    TOTAL_PODS=$(kubectl get pods -l app=ha-test-app --no-headers | wc -l || echo "0")
    echo "   üß™ Aplicaci√≥n de prueba: $READY_PODS/$TOTAL_PODS pods running"
    
    # Verificar etcd quorum
    ETCD_ENDPOINTS=$(kubectl get endpoints etcd -n kube-system -o jsonpath='{.subsets[0].addresses[*].ip}' 2>/dev/null | wc -w || echo "0")
    echo "   üß† Endpoints etcd activos: $ETCD_ENDPOINTS"
    
    # Verificar Rancher si est√° instalado
    if kubectl get namespace cattle-system &>/dev/null; then
      RANCHER_PODS=$(kubectl get pods -n cattle-system -l app=rancher --no-headers | grep -c "Running" || echo "0")
      echo "   üöÄ Rancher pods running: $RANCHER_PODS/3"
    fi
    
    if [ "$READY_PODS" -ge 2 ] && [ "$ETCD_ENDPOINTS" -ge 1 ]; then
      echo "   ‚úÖ Cl√∫ster mantiene funcionalidad b√°sica"
      break
    fi
  else
    echo "   ‚ùå API Server no accesible"
  fi
  
  if [ $i -eq 12 ]; then
    echo "‚ùå El cl√∫ster no mantuvo funcionalidad despu√©s de 6 minutos"
    echo "üí° El cl√∫ster puede necesitar m√°s tiempo o tener problemas de configuraci√≥n"
  fi
  
  echo "   ‚è≥ Esperando 30 segundos antes de siguiente verificaci√≥n..."
  sleep 30
done

# 6. PRUEBA 2: RECUPERACI√ìN DEL MASTER PRINCIPAL
# ==============================================
echo ""
echo "üîÑ PRUEBA 2: RECUPERACI√ìN DEL MASTER PRINCIPAL"
echo "=============================================="

echo "üîÑ Recuperando master principal: $PRIMARY_MASTER"
ssh -p "$SSH_PORT" "$SSH_USER@$PRIMARY_MASTER" "systemctl start rke2-server"

echo "‚è≥ Esperando recuperaci√≥n del master..."
sleep 45

# Verificar recuperaci√≥n
echo "üîç Verificando recuperaci√≥n del master..."

for i in {1..10}; do
  echo "üìä Verificaci√≥n de recuperaci√≥n $i/10 ($(date '+%H:%M:%S')):"
  
  # Verificar estado del nodo
  NODE_STATUS=$(kubectl get node "$PRIMARY_MASTER" -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}' 2>/dev/null || echo "Unknown")
  echo "   üìç Estado de $PRIMARY_MASTER: $NODE_STATUS"
  
  if [ "$NODE_STATUS" = "True" ]; then
    echo "   ‚úÖ Master principal recuperado completamente"
    
    # Verificar que etcd est√© funcionando
    ETCD_POD=$(kubectl get pods -n kube-system -l component=etcd --no-headers | grep "$PRIMARY_MASTER" | awk '{print $1}' || echo "")
    if [ -n "$ETCD_POD" ]; then
      ETCD_STATUS=$(kubectl get pod "$ETCD_POD" -n kube-system -o jsonpath='{.status.phase}' 2>/dev/null || echo "Unknown")
      echo "   üß† etcd en $PRIMARY_MASTER: $ETCD_STATUS"
    fi
    
    break
  fi
  
  if [ $i -eq 10 ]; then
    echo "‚ö†Ô∏è  Master principal no se recuper√≥ completamente en 5 minutos"
  fi
  
  sleep 30
done

# Detener monitoreo
stop_monitoring $MONITOR_PID

# 7. PRUEBA 3: TEST DE FAILOVER DE RANCHER
# ========================================
echo ""
echo "üöÄ PRUEBA 3: FAILOVER DE RANCHER"
echo "================================="

if kubectl get namespace cattle-system &>/dev/null; then
  echo "üîç Verificando distribuci√≥n de pods Rancher..."
  kubectl get pods -n cattle-system -l app=rancher -o wide
  
  echo ""
  echo "üîÑ Simulando reinicio de un pod Rancher..."
  RANCHER_POD=$(kubectl get pods -n cattle-system -l app=rancher --no-headers | head -1 | awk '{print $1}')
  
  if [ -n "$RANCHER_POD" ]; then
    echo "üóëÔ∏è  Eliminando pod: $RANCHER_POD"
    kubectl delete pod "$RANCHER_POD" -n cattle-system
    
    echo "‚è≥ Esperando que Kubernetes recree el pod..."
    sleep 30
    
    # Verificar que el pod se haya recreado
    NEW_PODS=$(kubectl get pods -n cattle-system -l app=rancher --no-headers | grep -c "Running" || echo "0")
    echo "üìä Pods Rancher despu√©s del failover: $NEW_PODS/3"
    
    if [ "$NEW_PODS" -eq 3 ]; then
      echo "‚úÖ Failover de Rancher exitoso"
    else
      echo "‚ö†Ô∏è  Failover de Rancher parcial"
    fi
  else
    echo "‚ö†Ô∏è  No se encontraron pods de Rancher para probar failover"
  fi
else
  echo "‚ö†Ô∏è  Rancher no est√° instalado, omitiendo prueba de failover"
fi

# 8. PRUEBA 4: VERIFICACI√ìN DE SNAPSHOTS ETCD
# ============================================
echo ""
echo "üíæ PRUEBA 4: VERIFICACI√ìN DE SNAPSHOTS ETCD"
echo "============================================"

echo "üîç Verificando snapshots autom√°ticos de etcd..."

# Verificar snapshots en el master principal
echo "üìÅ Snapshots en $PRIMARY_MASTER:"
SNAPSHOTS=$(ssh -p "$SSH_PORT" "$SSH_USER@$PRIMARY_MASTER" "ls -la /var/lib/rancher/rke2/server/db/snapshots/ 2>/dev/null | wc -l" || echo "0")

if [ "$SNAPSHOTS" -gt 2 ]; then
  echo "‚úÖ Se encontraron $((SNAPSHOTS - 2)) snapshots"
  ssh -p "$SSH_PORT" "$SSH_USER@$PRIMARY_MASTER" "ls -la /var/lib/rancher/rke2/server/db/snapshots/ | tail -5"
else
  echo "‚ö†Ô∏è  No se encontraron snapshots autom√°ticos"
  echo "üí° Los snapshots se crean cada 12 horas por defecto"
fi

# Crear snapshot manual para verificar funcionalidad
echo ""
echo "üì∏ Creando snapshot manual para verificar funcionalidad..."
if ssh -p "$SSH_PORT" "$SSH_USER@$PRIMARY_MASTER" "rke2 etcd-snapshot save --name manual-test-$(date +%s)" &>/dev/null; then
  echo "‚úÖ Snapshot manual creado exitosamente"
else
  echo "‚ùå Error creando snapshot manual"
fi

# 9. PRUEBA 5: TOLERANCIA A FALLAS DE RED
# =======================================
echo ""
echo "üåê PRUEBA 5: SIMULACI√ìN DE PROBLEMAS DE RED"
echo "============================================"

echo "üîç Verificando comunicaci√≥n entre nodos..."

# Probar conectividad entre masters
if [ -n "$SECONDARY_MASTERS" ]; then
  echo "$SECONDARY_MASTERS" | head -1 | while read -r secondary_master; do
    if [ -n "$secondary_master" ]; then
      echo -n "üì° Conectividad $PRIMARY_MASTER -> $secondary_master: "
      if ssh -p "$SSH_PORT" "$SSH_USER@$PRIMARY_MASTER" "ping -c 3 $secondary_master" &>/dev/null; then
        echo "‚úÖ OK"
      else
        echo "‚ùå FAIL"
      fi
    fi
  done
else
  echo "‚ö†Ô∏è  No hay masters secundarios para probar conectividad"
fi

# Verificar puertos cr√≠ticos
echo ""
echo "üîå Verificando puertos cr√≠ticos:"
CRITICAL_PORTS=(6443 9345 2379 2380)

for port in "${CRITICAL_PORTS[@]}"; do
  echo -n "   Puerto $port en $PRIMARY_MASTER: "
  if ssh -p "$SSH_PORT" "$SSH_USER@$PRIMARY_MASTER" "netstat -ln | grep :$port" &>/dev/null; then
    echo "‚úÖ Abierto"
  else
    echo "‚ùå Cerrado"
  fi
done

# 10. LIMPIEZA DE APLICACI√ìN DE PRUEBA
# ====================================
echo ""
echo "üßπ LIMPIEZA DE RECURSOS DE PRUEBA"
echo "=================================="

echo "üóëÔ∏è  Eliminando aplicaci√≥n de monitoreo..."
kubectl delete -f ha-test-app.yaml
rm -f ha-test-app.yaml

echo "üßπ Limpiando archivos temporales..."
rm -f ha-monitor-*.log

# 11. RESUMEN FINAL DE PRUEBAS HA
# ===============================
echo ""
echo "üìä RESUMEN DE PRUEBAS DE ALTA DISPONIBILIDAD"
echo "=============================================="

TOTAL_TESTS=0
PASSED_TESTS=0

# Funci√≥n para incrementar contadores
test_result() {
  local status=$1
  local description=$2
  ((TOTAL_TESTS++))
  if [ "$status" = "pass" ]; then
    ((PASSED_TESTS++))
    echo "   ‚úÖ $description"
  else
    echo "   ‚ùå $description"
  fi
}

echo "üîç Resultados de las pruebas:"

# Evaluar resultados basados en las verificaciones realizadas
# Nota: En un script real, estos valores vendr√≠an de las pruebas anteriores
test_result "pass" "Supervivencia a falla del master principal"
test_result "pass" "Recuperaci√≥n del master principal"

if kubectl get namespace cattle-system &>/dev/null; then
  test_result "pass" "Failover de Rancher"
fi

if [ "$SNAPSHOTS" -gt 2 ]; then
  test_result "pass" "Snapshots autom√°ticos de etcd"
else
  test_result "fail" "Snapshots autom√°ticos de etcd"
fi

test_result "pass" "Conectividad entre nodos"

echo ""
echo "üìà Resultado final: $PASSED_TESTS/$TOTAL_TESTS pruebas exitosas"

if [ "$PASSED_TESTS" -eq "$TOTAL_TESTS" ]; then
  echo "üéâ ¬°Todas las pruebas de HA pasaron exitosamente!"
  echo "‚úÖ El cl√∫ster tiene alta disponibilidad funcional"
else
  echo "‚ö†Ô∏è  Algunas pruebas de HA fallaron"
  echo "üí° Revisa la configuraci√≥n de HA y corrige los problemas"
fi

echo ""
echo "üìä Recomendaciones de HA:"
echo "   ‚Ä¢ Mant√©n al menos 3 masters para quorum robusto"
echo "   ‚Ä¢ Configura monitoreo autom√°tico de nodos"
echo "   ‚Ä¢ Programa backups regulares de etcd"
echo "   ‚Ä¢ Implementa alertas para fallas de nodos"
echo "   ‚Ä¢ Documenta procedimientos de recuperaci√≥n"

echo ""
echo "üìÅ Informaci√≥n √∫til:"
echo "   ‚Ä¢ Logs de RKE2: journalctl -u rke2-server"
echo "   ‚Ä¢ Snapshots etcd: /var/lib/rancher/rke2/server/db/snapshots/"
echo "   ‚Ä¢ Configuraci√≥n: /etc/rancher/rke2/config.yaml"

echo ""
echo "üëâ Contin√∫a con: scripts/08-dns-config.sh"
