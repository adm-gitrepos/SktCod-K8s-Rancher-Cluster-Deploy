# üß≠ Documentaci√≥n T√©cnica Completa - RKE2 + Rancher HA v2.0

Este documento centraliza toda la informaci√≥n t√©cnica actualizada, arquitectura mejorada, configuraci√≥n centralizada, funciones helper y extensiones del instalador automatizado de cl√∫steres RKE2 en alta disponibilidad con Rancher.

---

## üÜï Novedades de la Versi√≥n 2.0

### ‚ú® **Refactorizaci√≥n Completa**
- **Configuraci√≥n centralizada** en `.env` con formato JSON para nodos
- **Funciones helper** reutilizables en `scripts/node-helpers.sh`
- **Auto-instalaci√≥n** de dependencias (jq, helm, etc.)
- **Validaci√≥n exhaustiva** en cada script
- **Escalabilidad mejorada** para agregar/quitar nodos f√°cilmente

### üîß **Arquitectura Mejorada**
- **Un solo punto de configuraci√≥n** para toda la infraestructura
- **Consistencia garantizada** entre todos los scripts
- **Mantenimiento simplificado** con funciones centralizadas
- **Flexibilidad total** en tipos y cantidad de nodos

---

## üß± Arquitectura General

```
+-------------------------------+
|          NGINX Plus          |
| (Load Balancer 80/443/9345)  |
+-------------------------------+
           |       |
    +------+-------+------+
    | prd3appk8sm1       |
    | prd3appk8sm2       |  <-- Master nodes (RKE2 Server)
    | prd3appk8sm3       |      Auto-detectados desde NODES_CONFIG
    +--------------------+
           |       |
    +------+-------+------+
    | prd3appk8sw1       |  <-- Worker nodes (Rancher pods)
    | prd3appk8sw2       |      Configuraci√≥n din√°mica
    | prd3appk8sw3       |
    +--------------------+
           |       |
    +------+-------+------+
    | prd3appk8ss1       |  <-- Storage nodes (Ceph OSD)
    | prd3appk8ss2       |      Auto-configuraci√≥n de discos
    | prd3appk8ss3       |
    +--------------------+
```

### üîß **Caracter√≠sticas Din√°micas:**
- **Balanceo autom√°tico** hacia puertos `6443`, `9345`, `80`, `443`
- **Rancher HA** desplegado autom√°ticamente en nodos worker
- **Ceph distribuido** en nodos con label `ceph-node=true`
- **MetalLB** con pools de IP configurables

---

## üèóÔ∏è Configuraci√≥n Centralizada

### üìÑ **Archivo `.env` - Configuraci√≥n Completa**

```dotenv
# üåç Configuraci√≥n B√°sica del Cl√∫ster
ROOT_PASSWORD=TuPasswordSeguraAqui
LB_IP=1.1.1.1                          # IP del LoadBalancer externo
SSH_PORT=22                             # Puerto SSH (default: 22)
SSH_USER=root                           # Usuario SSH (default: root)
RANCHER_DOMAIN=rancher.midominio.com    # Dominio para Rancher UI
BOOTSTRAP_PASSWORD=AdminPassword123     # Password inicial de Rancher
RKE2_VERSION=v1.32.1+rke2r1            # Versi√≥n espec√≠fica de RKE2
RANCHER_VERSION=v2.11.1                # Versi√≥n espec√≠fica de Rancher
CLUSTER_TOKEN=TokenSuperSeguro123       # Token √∫nico del cl√∫ster
METALLB_IP_RANGE=1.1.1.200-1.1.1.210   # Rango de IPs para MetalLB

# üèóÔ∏è CONFIGURACI√ìN DIN√ÅMICA DE NODOS (JSON)
# ============================================
# Formato: {"hostname": {"ip": "x.x.x.x", "type": "master|worker|storage", "primary": true/false}}
NODES_CONFIG='{
  "prd3appk8sm1": {"ip": "1.1.1.20", "type": "master", "primary": true},
  "prd3appk8sm2": {"ip": "1.1.1.21", "type": "master", "primary": false},
  "prd3appk8sm3": {"ip": "1.1.1.22", "type": "master", "primary": false},
  "prd3appk8sw1": {"ip": "1.1.1.30", "type": "worker", "primary": false},
  "prd3appk8sw2": {"ip": "1.1.1.31", "type": "worker", "primary": false},
  "prd3appk8sw3": {"ip": "1.1.1.32", "type": "worker", "primary": false},
  "prd3appk8ss1": {"ip": "1.1.1.40", "type": "storage", "primary": false},
  "prd3appk8ss2": {"ip": "1.1.1.41", "type": "storage", "primary": false},
  "prd3appk8ss3": {"ip": "1.1.1.42", "type": "storage", "primary": false}
}'
```

### üîë **Tipos de Nodos Soportados:**

| Tipo | Descripci√≥n | Caracter√≠sticas | Servicios |
|------|-------------|-----------------|-----------|
| `master` | Nodos control plane | etcd, API server, scheduler | RKE2 Server |
| `worker` | Nodos de aplicaciones | Rancher UI, aplicaciones usuario | RKE2 Agent |
| `storage` | Nodos de almacenamiento | Ceph OSDs, almacenamiento persistente | RKE2 Agent + Ceph |

### üîß **Configuraci√≥n Adicional por Nodo:**
- **`primary: true`**: Solo para UN master (donde se ejecuta la instalaci√≥n inicial)
- **`ip`**: Direcci√≥n IP accesible via SSH
- **`type`**: Determina qu√© servicios se instalan en cada nodo

---

## üß∞ Funciones Helper Centralizadas

### üìÑ **`scripts/node-helpers.sh` - Biblioteca de Funciones**

```bash
# Funciones principales disponibles:
get_nodes_by_type()          # Obtiene nodos por tipo (master/worker/storage)
get_node_ip()                # Obtiene IP de un nodo espec√≠fico
get_primary_master()         # Obtiene el nodo master principal
get_secondary_masters()      # Obtiene masters secundarios
get_all_nodes_with_ips()     # Obtiene todos los nodos con formato IP:HOSTNAME
validate_nodes_config()      # Valida configuraci√≥n JSON y prerequisitos
generate_ceph_nodes_yaml()   # Genera YAML de Ceph din√°micamente
show_nodes_summary()         # Muestra resumen de configuraci√≥n
```

### üîÑ **Ventajas de las Funciones Helper:**
- ‚úÖ **Reutilizaci√≥n**: C√≥digo consistente entre scripts
- ‚úÖ **Mantenimiento**: Un solo lugar para l√≥gica de nodos
- ‚úÖ **Validaci√≥n**: Verificaci√≥n autom√°tica de configuraci√≥n
- ‚úÖ **Flexibilidad**: F√°cil extensi√≥n para nuevos tipos de nodos

---

## üß≠ Modos de Instalaci√≥n Mejorados

El script `install-all.sh` permite ejecutar el despliegue completo o parcial con validaciones autom√°ticas:

| Modo         | Scripts Ejecutados | Descripci√≥n |
| ------------ | ------------------ | ----------- |
| `full`       | 00-08 (todos)     | Stack completo: RKE2 + Ceph + MetalLB + Rancher |
| `no-rancher` | 00-04, 06-07      | Todo excepto Rancher (para cl√∫steres base) |
| `only-k8s`   | 00-02             | Solo RKE2 (para testing o configuraci√≥n manual) |

### üîß **Validaciones Autom√°ticas:**
- **jq disponible**: Auto-instala si no est√° presente
- **Configuraci√≥n JSON**: Valida formato y estructura
- **Prerequisitos**: RAM, disco, conectividad, m√≥dulos kernel

---

## üìÇ Estructura de Scripts Refactorizada

```bash
scripts/
‚îú‚îÄ‚îÄ node-helpers.sh              # üÜï Funciones centralizadas
‚îú‚îÄ‚îÄ 00-check-prereqs.sh          # Auto-instalaci√≥n de dependencias
‚îú‚îÄ‚îÄ 01-setup-ssh.sh             # SSH din√°mico por configuraci√≥n
‚îú‚îÄ‚îÄ 02-install-cluster.sh       # RKE2 con nodos auto-detectados
‚îú‚îÄ‚îÄ 03-install-ceph.sh          # Ceph con configuraci√≥n din√°mica
‚îú‚îÄ‚îÄ 04-install-metallb.sh       # MetalLB con validaci√≥n de red
‚îú‚îÄ‚îÄ 05-install-rancher.sh       # Rancher HA auto-configurado
‚îú‚îÄ‚îÄ 06-verify-installation.sh   # Verificaci√≥n exhaustiva
‚îú‚îÄ‚îÄ 07-test-ha.sh               # Pruebas reales de HA con monitoreo
‚îú‚îÄ‚îÄ 08-dns-config.sh            # DNS y resumen final
```

### üîß **Mejoras por Script:**

#### **00-check-prereqs.sh**
- ‚úÖ Auto-instalaci√≥n de `jq`, `helm`, `sshpass`
- ‚úÖ Validaci√≥n de `NODES_CONFIG` JSON
- ‚úÖ Verificaci√≥n din√°mica de nodos por tipo
- ‚úÖ Carga autom√°tica de m√≥dulos kernel

#### **01-setup-ssh.sh**
- ‚úÖ Detecci√≥n autom√°tica de nodos desde configuraci√≥n
- ‚úÖ Verificaci√≥n post-configuraci√≥n
- ‚úÖ Configuraci√≥n SSH optimizada

#### **02-install-cluster.sh**
- ‚úÖ Master principal auto-detectado
- ‚úÖ Configuraci√≥n espec√≠fica por tipo de nodo
- ‚úÖ Monitoreo de progreso en tiempo real
- ‚úÖ Validaci√≥n de quorum etcd

#### **03-install-ceph.sh**
- ‚úÖ Nodos storage auto-detectados
- ‚úÖ Generaci√≥n din√°mica de CephCluster YAML
- ‚úÖ Validaci√≥n de discos en cada nodo storage
- ‚úÖ Configuraci√≥n autom√°tica de r√©plicas

#### **04-install-metallb.sh**
- ‚úÖ Validaci√≥n de rango de IPs
- ‚úÖ Verificaci√≥n de conectividad de red
- ‚úÖ Prueba autom√°tica de LoadBalancer

#### **05-install-rancher.sh**
- ‚úÖ Auto-instalaci√≥n de Helm si no existe
- ‚úÖ Configuraci√≥n HA con 3 replicas
- ‚úÖ Certificados SSL autom√°ticos
- ‚úÖ Verificaci√≥n de acceso HTTPS

#### **06-verify-installation.sh**
- ‚úÖ Verificaci√≥n por tipos de nodos
- ‚úÖ Aplicaci√≥n de prueba integral
- ‚úÖ Validaci√≥n de todos los componentes
- ‚úÖ Sistema de puntuaci√≥n

#### **07-test-ha.sh**
- ‚úÖ Pruebas reales de fallo de master
- ‚úÖ Monitoreo continuo en background
- ‚úÖ Verificaci√≥n de recuperaci√≥n autom√°tica
- ‚úÖ Pruebas de failover de Rancher

#### **08-dns-config.sh**
- ‚úÖ Configuraci√≥n DNS autom√°tica
- ‚úÖ Validaci√≥n de conectividad web
- ‚úÖ Extracci√≥n de credenciales reales
- ‚úÖ Resumen final completo

---

## üß™ Validaciones Integradas Mejoradas

### üîç **Verificaciones Autom√°ticas:**

#### **Pre-instalaci√≥n:**
- ‚úÖ Validaci√≥n de formato JSON en `NODES_CONFIG`
- ‚úÖ Verificaci√≥n de conectividad SSH a todos los nodos
- ‚úÖ Validaci√≥n de prerequisitos por tipo de nodo
- ‚úÖ Auto-instalaci√≥n de dependencias faltantes

#### **Durante Instalaci√≥n:**
- ‚úÖ Monitoreo en tiempo real de procesos
- ‚úÖ Verificaci√≥n de estado despu√©s de cada paso
- ‚úÖ Timeouts apropiados para cada componente
- ‚úÖ Logs detallados con timestamps

#### **Post-instalaci√≥n:**
- ‚úÖ Verificaci√≥n exhaustiva de todos los componentes
- ‚úÖ Aplicaci√≥n de prueba con PVC + LoadBalancer
- ‚úÖ Pruebas reales de Alta Disponibilidad
- ‚úÖ Validaci√≥n de DNS y conectividad web

### üîÑ **Pruebas de Alta Disponibilidad:**
- **Fallo simulado** de master principal con monitoreo continuo
- **Verificaci√≥n de quorum** etcd durante fallos
- **Failover de Rancher** con recreaci√≥n autom√°tica de pods
- **Recuperaci√≥n autom√°tica** y rejoining al cl√∫ster
- **Snapshots etcd** autom√°ticos y manuales

---

## ‚ö†Ô∏è Prerequisitos Cr√≠ticos Actualizados

### üî¥ **Configuraci√≥n Obligatoria Antes de Ejecutar:**

#### **1. Archivo `.env` Configurado**
```bash
# Copiar y configurar
cp .env.example .env
nano .env

# Validar configuraci√≥n JSON
echo "$NODES_CONFIG" | jq .
```

#### **2. DNS Configurado**
```bash
# Verificar resoluci√≥n
nslookup $RANCHER_DOMAIN

# O configurar temporalmente
echo "$LB_IP $RANCHER_DOMAIN" >> /etc/hosts
```

#### **3. NGINX Plus (si se usa como proxy externo)**
- Upstreams configurados para puertos `6443`, `9345`, `80`, `443`
- Ver [`docs/nginx-plus.md`](./nginx-plus.md) para configuraci√≥n detallada

#### **4. Acceso SSH Unificado**
- Misma contrase√±a root en todos los nodos
- Conectividad SSH desde el nodo master principal

### üîß **Auto-instalaci√≥n de Dependencias**
Los scripts autom√°ticamente instalan:
- `jq` (requerido para procesar JSON)
- `helm` (para Rancher y cert-manager)
- `sshpass`, `curl`, `wget`, `tar`

---

## üöÄ Flujo de Instalaci√≥n Recomendado

### **Paso 1: Preparaci√≥n**
```bash
# Clonar repositorio
git clone <repo-url>
cd rke2-rancher-ha-installer

# Configurar variables
cp .env.example .env
nano .env  # Configurar NODES_CONFIG y dem√°s variables
```

### **Paso 2: Validaci√≥n**
```bash
# Verificar prerequisitos (auto-instala dependencias)
bash scripts/00-check-prereqs.sh
```

### **Paso 3: Instalaci√≥n**
```bash
# Opci√≥n A: Instalaci√≥n completa autom√°tica
./install-all.sh full

# Opci√≥n B: Paso a paso para debugging
bash scripts/01-setup-ssh.sh
bash scripts/02-install-cluster.sh
bash scripts/03-install-ceph.sh
bash scripts/04-install-metallb.sh
bash scripts/05-install-rancher.sh
bash scripts/06-verify-installation.sh
bash scripts/07-test-ha.sh
bash scripts/08-dns-config.sh
```

### **Paso 4: Verificaci√≥n Final**
```bash
# Acceder a Rancher
curl -k https://$RANCHER_DOMAIN

# Verificar cl√∫ster
kubectl get nodes -o wide
kubectl get pods -A
```

---

## üîß Configuraci√≥n Avanzada

### **Agregar Nuevos Nodos**
```bash
# 1. Actualizar .env
NODES_CONFIG='{
  "existing-nodes": {...},
  "new-node": {"ip": "10.0.0.100", "type": "worker", "primary": false}
}'

# 2. Re-ejecutar scripts relevantes
bash scripts/01-setup-ssh.sh     # SSH al nuevo nodo
bash scripts/02-install-cluster.sh # Agregar al cl√∫ster
```

### **Cambiar Tipos de Nodos**
```bash
# Modificar tipo en NODES_CONFIG
"node-name": {"ip": "...", "type": "storage", "primary": false}

# Re-ejecutar configuraci√≥n
bash scripts/02-install-cluster.sh
bash scripts/03-install-ceph.sh  # Si se agreg√≥ storage
```

### **Escalado de Componentes**
```bash
# Aumentar r√©plicas de Rancher
kubectl -n cattle-system scale deployment rancher --replicas=5

# Agregar m√°s OSDs de Ceph (autom√°tico al agregar nodos storage)
# Expandir pool de MetalLB (modificar METALLB_IP_RANGE)
```

---

## üß© Extensiones Posibles

### **Monitoreo y Observabilidad**
```bash
# Prometheus + Grafana
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm install prometheus prometheus-community/kube-prometheus-stack

# Logging con ELK
kubectl apply -f https://raw.githubusercontent.com/elastic/cloud-on-k8s/main/config/crds.yaml
```

### **GitOps y CI/CD**
```bash
# ArgoCD
kubectl create namespace argocd
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml

# Fleet (integrado con Rancher)
# Se configura desde la UI de Rancher
```

### **Seguridad Avanzada**
```bash
# Falco para runtime security
helm repo add falcosecurity https://falcosecurity.github.io/charts
helm install falco falcosecurity/falco

# OPA Gatekeeper para policies
kubectl apply -f https://raw.githubusercontent.com/open-policy-agent/gatekeeper/release-3.14/deploy/gatekeeper.yaml
```

### **Backup Automatizado**
```bash
# Velero para backup de aplicaciones
wget https://github.com/vmware-tanzu/velero/releases/download/v1.12.0/velero-v1.12.0-linux-amd64.tar.gz
tar -xvf velero-v1.12.0-linux-amd64.tar.gz
./velero install --provider aws --bucket mybucket --secret-file ./credentials-velero
```

---

## üîç Troubleshooting Avanzado

### **Problemas de Configuraci√≥n JSON**
```bash
# Validar JSON
echo "$NODES_CONFIG" | jq .

# Formatear JSON
echo "$NODES_CONFIG" | jq . > nodes-formatted.json

# Verificar tipos permitidos
echo "$NODES_CONFIG" | jq -r 'to_entries[] | select(.value.type | contains("master", "worker", "storage") | not)'
```

### **Problemas de SSH**
```bash
# Debug SSH
ssh -vvv -p $SSH_PORT $SSH_USER@<node-ip>

# Verificar configuraci√≥n SSH
bash scripts/node-helpers.sh
source scripts/node-helpers.sh
show_nodes_summary
```

### **Problemas de Red**
```bash
# Verificar conectividad entre nodos
for node in $(get_nodes_by_type "master"); do
  echo "Testing $node"
  ssh $SSH_USER@$node "ping -c 3 <other-node-ip>"
done

# Verificar puertos cr√≠ticos
nmap -p 6443,9345,2379,2380 <master-ip>
```

### **Problemas de Ceph**
```bash
# Estado detallado de Ceph
kubectl -n rook-ceph exec -it deploy/rook-ceph-tools -- ceph status
kubectl -n rook-ceph exec -it deploy/rook-ceph-tools -- ceph osd status
kubectl -n rook-ceph exec -it deploy/rook-ceph-tools -- ceph df
```

### **Problemas de Rancher**
```bash
# Logs de Rancher
kubectl -n cattle-system logs -f deployment/rancher

# Reiniciar Rancher
kubectl -n cattle-system rollout restart deployment/rancher

# Verificar certificados
kubectl -n cattle-system get certificates
kubectl -n cattle-system describe certificate <cert-name>
```

---

## üìä M√©tricas y Monitoreo

### **Comandos de Estado**
```bash
# Estado general del cl√∫ster
kubectl cluster-info
kubectl get nodes -o wide
kubectl top nodes  # Requiere metrics-server

# Estado de componentes cr√≠ticos
kubectl get pods -n kube-system | grep -E "(etcd|api|scheduler|controller)"
kubectl get events --sort-by=.metadata.creationTimestamp | tail -20

# Estado de almacenamiento
kubectl get pv,pvc -A
kubectl get storageclass
kubectl -n rook-ceph get cephcluster

# Estado de red
kubectl get svc -A | grep LoadBalancer
kubectl -n metallb-system get ipaddresspool
```

### **Logs Importantes**
```bash
# RKE2
journalctl -u rke2-server -f
journalctl -u rke2-agent -f

# Contenedores del sistema
kubectl logs -n kube-system -l component=etcd
kubectl logs -n kube-system -l component=kube-apiserver

# Aplicaciones
kubectl logs -n cattle-system -l app=rancher
kubectl logs -n rook-ceph -l app=rook-ceph-mon
```

---

## üîÑ Migraci√≥n y Upgrades

### **Migraci√≥n desde Configuraci√≥n Hardcodeada**
```bash
# 1. Backup configuraci√≥n actual
cp scripts/ scripts-backup/

# 2. Crear NODES_CONFIG desde configuraci√≥n existente
# Extraer IPs y hostnames de scripts antiguos
grep -r "ssh.*@" scripts-backup/ | grep -o "[0-9]\+\.[0-9]\+\.[0-9]\+\.[0-9]\+"

# 3. Construir JSON manualmente o con script
cat > migrate-config.sh <<'EOF'
#!/bin/bash
# Script de migraci√≥n ejemplo
MASTERS=("prd3appk8sm1:1.1.1.20" "prd3appk8sm2:1.1.1.21")
WORKERS=("prd3appk8sw1:1.1.1.30" "prd3appk8sw2:1.1.1.31")

echo "NODES_CONFIG='{"
for i, master in ${MASTERS[@]}; do
  # Generar JSON...
done
echo "}'"
EOF
```

### **Upgrade de RKE2**
```bash
# 1. Actualizar versi√≥n en .env
RKE2_VERSION=v1.33.0+rke2r1

# 2. Upgrade nodo por nodo
for master in $(get_nodes_by_type "master"); do
  ssh $SSH_USER@$master "
    systemctl stop rke2-server
    curl -sfL https://get.rke2.io | INSTALL_RKE2_VERSION=$RKE2_VERSION sh -
    systemctl start rke2-server
  "
  sleep 60  # Esperar estabilizaci√≥n
done
```

### **Upgrade de Rancher**
```bash
# Actualizar versi√≥n en .env
RANCHER_VERSION=v2.12.0

# Upgrade con Helm
helm upgrade rancher rancher-latest/rancher \
  --namespace cattle-system \
  --version $RANCHER_VERSION
```

---

## üìö Referencias Cruzadas

* **[README.md](../README.md)**: Gu√≠a de instalaci√≥n y configuraci√≥n b√°sica
* **[nginx-plus.md](./nginx-plus.md)**: Configuraci√≥n de LoadBalancer externo
* **`.env.example`**: Variables de configuraci√≥n con ejemplos
* **Logs de instalaci√≥n**: `logs/` - Debugging detallado por script

---

## üîÆ Roadmap y Futuras Mejoras

### **Versi√≥n 2.1 (Planeada)**
- [ ] Soporte para m√∫ltiples proveedores cloud (AWS, Azure, GCP)
- [ ] Auto-scaling autom√°tico de nodos
- [ ] Integraci√≥n con Terraform/Ansible
- [ ] Dashboard web para configuraci√≥n
- [ ] Backup autom√°tico programado

### **Versi√≥n 2.2 (Investigaci√≥n)**
- [ ] Soporte para Kubernetes multi-cluster
- [ ] Integraci√≥n con service mesh (Istio/Linkerd)
- [ ] Compliance autom√°tico (CIS benchmarks)
- [ ] AI/ML workloads optimization

---

## üìú Licencia

Este proyecto est√° licenciado bajo los t√©rminos de la [Licencia MIT](../LICENSE), lo que permite su uso, copia, modificaci√≥n y distribuci√≥n con fines personales, acad√©micos o comerciales.

> **Autor√≠a**: Este software fue creado y es mantenido por [@SktCod.ByChisto](https://github.com/adm-gitrepos).  
> Aunque es de c√≥digo abierto, se agradece el reconocimiento correspondiente en derivados o menciones p√∫blicas.

---

## üë§ Autor

Desarrollado por [@SktCod.ByChisto](https://github.com/adm-gitrepos)  
¬© 2025 ‚Äì Todos los derechos reservados.
